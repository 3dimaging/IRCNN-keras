{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IRCNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y4j-cShYT6Mz"
      },
      "source": [
        "## Inception Recurrent Convolutional Neural Network (IRCNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7PLwcGm5jHz",
        "colab_type": "code",
        "outputId": "ae0d9538-3d52-4a4a-efd2-f66d02554054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sys\n",
        "import warnings\n",
        "# Keras Core\n",
        "from keras.layers.convolutional import MaxPooling2D, Convolution2D, AveragePooling2D\n",
        "from keras.layers.pooling import GlobalAveragePooling2D\n",
        "from keras.layers import Input, Dropout, Dense, Flatten, Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers import Add\n",
        "from keras import regularizers\n",
        "from keras import initializers\n",
        "from keras.models import Model\n",
        "\n",
        "# Backend\n",
        "from keras import backend as K\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mohJ1GonbCGp",
        "colab_type": "text"
      },
      "source": [
        "#### Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdmOO-QX5o3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convolution 2D with batch norm\n",
        "def conv2d_bn(x, nb_filter, num_row, num_col,\n",
        "            padding='same', strides=(1, 1), use_bias=False):\n",
        "  \"\"\"\n",
        "  Utility function to apply conv + BN. \n",
        "  (Slightly modified from https://github.com/fchollet/keras/blob/master/keras/applications/inception_v3.py)\n",
        "  \"\"\"\n",
        "  if K.image_data_format() == 'channels_first':\n",
        "    channel_axis = 1\n",
        "  else:\n",
        "    channel_axis = -1\n",
        "  x = Convolution2D(nb_filter, (num_row, num_col),\n",
        "                    strides=strides,\n",
        "                    padding=padding,\n",
        "                    use_bias=use_bias,\n",
        "                    kernel_regularizer=regularizers.l2(0.00004),\n",
        "                    kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(x)\n",
        "  x = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(x)\n",
        "  x = Activation('relu')(x)\n",
        "  return x\n",
        "\n",
        "# Recurrent convolutional layer\n",
        "def RCL(input, kernel_size, filedepth):\n",
        "  if K.image_data_format() == 'channels_first':\n",
        "    channel_axis = 1\n",
        "  else:\n",
        "    channel_axis = -1\n",
        "\n",
        "  conv1 = Convolution2D(filters=filedepth, kernel_size=kernel_size, strides=(1, 1), padding='same',\n",
        "                 kernel_regularizer=regularizers.l2(0.00004),\n",
        "                 kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(input)\n",
        "\n",
        "  stack2 = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(conv1)\n",
        "  stack2 = Activation('relu')(stack2)\n",
        "\n",
        "  RCL = Convolution2D(filters=filedepth, kernel_size=kernel_size, strides=(1, 1), padding='same', \n",
        "                 kernel_regularizer=regularizers.l2(0.00004),\n",
        "                 kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))\n",
        "\n",
        "  conv2 = RCL(stack2)\n",
        "  stack3 = Add()([conv1, conv2])\n",
        "  stack4 = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(stack3)\n",
        "  stack4 = Activation('relu')(stack4)\n",
        "\n",
        "\n",
        "  conv3 = Convolution2D(filters=filedepth, kernel_size=kernel_size, strides=(1, 1), padding='same',\n",
        "                 weights=RCL.get_weights(),\n",
        "                 kernel_regularizer=regularizers.l2(0.00004),\n",
        "                 kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(stack4)\n",
        "  stack5 = Add()([conv1, conv3])\n",
        "  stack6 = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(stack5)\n",
        "  stack6 = Activation('relu')(stack6)\n",
        "\n",
        "\n",
        "  conv4 = Convolution2D(filters=filedepth, kernel_size=kernel_size, strides=(1, 1), padding='same',\n",
        "                 weights=RCL.get_weights(),\n",
        "                 kernel_regularizer=regularizers.l2(0.00004),\n",
        "                 kernel_initializer=initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='normal', seed=None))(stack6)\n",
        "  stack7 = Add()([conv1, conv4])\n",
        "  stack8 = BatchNormalization(axis=channel_axis, momentum=0.9997, scale=False)(stack7)\n",
        "  stack8 = Activation('relu')(stack8)\n",
        "\n",
        "  return stack8\n",
        "\n",
        "\n",
        "def IRCNN_block(input):\n",
        "  if K.image_data_format() == 'channels_first':\n",
        "    channel_axis = 1\n",
        "  else:\n",
        "    channel_axis = -1\n",
        "\n",
        "  branch_0 = RCL(input, (1, 1), 64)\n",
        "\n",
        "  branch_1 = RCL(input, (3, 3), 128)\n",
        "\n",
        "  branch_2 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input)\n",
        "  branch_2 = RCL(branch_2, (1, 1), 64)\n",
        "\n",
        "  x = concatenate([branch_0, branch_1, branch_2], axis=channel_axis)\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwXAemFKbcKr",
        "colab_type": "text"
      },
      "source": [
        "Below I have used 3 IRCNN blocks with transitional layers as per the paper. You can change this according to your requirement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88nWq3rubXcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def IRCNN_base(input):\n",
        "\n",
        "  if K.image_data_format() == 'channels_first':\n",
        "#     inputShape = (3, 256, 256)\n",
        "    channel_axis = 1\n",
        "  else:\n",
        "#     inputShape = (256, 256, 3)\n",
        "    channel_axis = -1\n",
        "\n",
        "  # Input Shape is 3 x 256 x 256\n",
        "  net = Convolution2D(32, (3, 3), strides=(2,2), padding='valid')(input)\n",
        "  net = conv2d_bn(net, 32, 3, 3, padding='valid')\n",
        "  net = conv2d_bn(net, 64, 3, 3)\n",
        "\n",
        "  net = IRCNN_block(input)\n",
        "                 \n",
        "  net = conv2d_bn(net, 32, 3, 3, strides=(2,2), padding='valid')\n",
        "  net = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
        "  net = Dropout(0.5)(net)\n",
        "\n",
        "  net = IRCNN_block(input)\n",
        "                 \n",
        "  net = conv2d_bn(net, 32, 3, 3, strides=(2,2), padding='valid')\n",
        "  net = MaxPooling2D((3,3), strides=(2,2), padding='valid')(net)\n",
        "  net = Dropout(0.5)(net)\n",
        "                 \n",
        "  net = IRCNN_block(input)\n",
        "                 \n",
        "  net = conv2d_bn(net, 32, 3, 3, strides=(2,2), padding='valid')\n",
        "  net = GlobalAveragePooling2D()(net)\n",
        "  net = Dropout(0.5)(net)\n",
        "  \n",
        "  \n",
        "  return net\t\t\t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHqGqiMIoGlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change this according to your dataset\n",
        "image_size = 256\n",
        "no_classes = 3\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "  inputs = Input(shape = (3, image_size, image_size))\n",
        "else:\n",
        "  inputs = Input(shape = (image_size, image_size, 3))\n",
        "\n",
        "# x = Convolution2D(32, (3, 3), strides=(2,2), padding='valid')(inputs)\n",
        "x = IRCNN_base(x)\n",
        "x = Dense(units=no_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, x, name='IRCNN')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYHzanvs8N0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T8j-sPf8p4Yx",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "from keras import callbacks\n",
        "import math\n",
        "\n",
        "# adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
        "sgd = optimizers.SGD(lr=0.01)\n",
        "\n",
        "filepath=\"./weights-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "\n",
        "mcp = callbacks.ModelCheckpoint(filepath=filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [mcp]\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZUbn7lDb21q",
        "colab_type": "text"
      },
      "source": [
        "Load your dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fc655dea-8a77-4df1-de18-14ead9b66048",
        "id": "nUSWmOqfp4Yn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "aug = ImageDataGenerator(rotation_range=45,\n",
        "                         fill_mode='wrap',\n",
        "                         samplewise_center=True,\n",
        "                         samplewise_std_normalization=True,\n",
        "                         horizontal_flip=True, \n",
        "                         vertical_flip=True, \n",
        "                         validation_split=0.15)\n",
        "bs = 16\n",
        "train_path = './train'\n",
        "\n",
        "train_generator = aug.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=bs,\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = aug.flow_from_directory(\n",
        "    train_path, # same directory as training data\n",
        "    target_size=(256, 256),\n",
        "    batch_size=bs,\n",
        "    subset='validation') # set as validation data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6358 images belonging to 3 classes.\n",
            "Found 1122 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XT2zm3q7p4Yv",
        "colab": {}
      },
      "source": [
        "train_step=train_generator.n//train_generator.batch_size\n",
        "valid_step=validation_generator.n//validation_generator.batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZMU1ylNb5Be",
        "colab_type": "text"
      },
      "source": [
        "Training..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bu95wKXcp4Y3",
        "colab": {}
      },
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_step,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=valid_step,\n",
        "    epochs=20,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=1)\n",
        "\n",
        "# make lr=0.001 after 20 epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rijstjXinbJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}